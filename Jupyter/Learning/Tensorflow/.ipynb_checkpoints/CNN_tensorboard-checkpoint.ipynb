{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\asm\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "LOGDIR = 'C:/ASM/DevData/learning/tensorboard/graphs'\n",
    "mnist = input_data.read_data_sets('/tmp/data/', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "#Network Parameters\n",
    "num_input = 784\n",
    "num_classes = 10\n",
    "keep_prob_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(x, size_in, size_out, ksize, strides, padding, name):    \n",
    "    strides = [1, strides[0], strides[1], 1]    \n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(tf.truncated_normal([ksize[0], ksize[1], size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"b\")\n",
    "        conv = tf.nn.conv2d(x, W, strides=strides, padding=padding)\n",
    "        output = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"weights\", W)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"outputs\", output)\n",
    "        return output\n",
    "    \n",
    "def maxpool_layer(x, ksize, strides, padding, name):\n",
    "    ksize = [1, ksize[0], ksize[1], 1]\n",
    "    strides = [1, strides[0], strides[1], 1]\n",
    "    with tf.name_scope(name):\n",
    "        output = tf.nn.max_pool(x, ksize, strides, padding)\n",
    "        tf.summary.histogram(\"outputs\", output)\n",
    "        return output\n",
    "    \n",
    "def fc_layer(x, size_in, size_out, name, relu=False):\n",
    "    with tf.name_scope(name):\n",
    "        W = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"b\")\n",
    "        output = tf.matmul(x, W) + b\n",
    "        if relu:\n",
    "            output = tf.nn.relu(output)\n",
    "            \n",
    "        tf.summary.histogram('weights', W)\n",
    "        tf.summary.histogram('biases', b)\n",
    "        tf.summary.histogram('outputs', output)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convnet_model(x, keep_prob):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    conv_1 = conv_layer(x, size_in=1, size_out=32, ksize=[5,5], strides=[1,1], padding=\"SAME\", name='conv_1')\n",
    "    maxpool_1 = maxpool_layer(conv_1, ksize=[2,2], strides=[2,2], padding=\"SAME\", name=\"maxpool_1\")\n",
    "    \n",
    "    conv_2 = conv_layer(maxpool_1, size_in=32, size_out=64, ksize=[5,5], strides=[1,1], padding=\"SAME\", name='conv_2')\n",
    "    maxpool_2 = maxpool_layer(conv_2, ksize=[2,2], strides=[2,2], padding=\"SAME\", name=\"maxpool_2\")\n",
    "    \n",
    "    flattened = tf.reshape(maxpool_2, shape=[-1, 7*7*64])\n",
    "    \n",
    "    fc_1 = fc_layer(flattened, 7*7*64, 128, name='FC_1', relu=True)\n",
    "    fcdrop_1 = tf.nn.dropout(fc_1, keep_prob, name='fcdrop_1')    \n",
    "    logits = fc_layer(fcdrop_1, 128, 10, name='FC_2')\n",
    "    \n",
    "    return logits      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, num_input], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, [None, num_classes], name=\"y\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-ece6731c4c93>:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = convnet_model(x, keep_prob)\n",
    "prediction = tf.nn.softmax(logits, name=\"prediction\") \n",
    "\n",
    "\n",
    "loss_op = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"loss_op\")\n",
    "tf.summary.scalar(\"loss_op_summary\", loss_op)\n",
    "\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss_op, name=\"train_step\")\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1), name=\"correct_prediction\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "tf.summary.scalar(\"accuracy_summary\", accuracy)\n",
    "\n",
    "summ = tf.summary.merge_all()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        print('Creating directory: ', path)\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Minibatch Loss: 4.9123, Training accuracy: 0.070\n",
      "Epoch: 2, Minibatch Loss: 3.0230, Training accuracy: 0.102\n",
      "Epoch: 4, Minibatch Loss: 2.7250, Training accuracy: 0.102\n",
      "Epoch: 6, Minibatch Loss: 2.2063, Training accuracy: 0.188\n",
      "Epoch: 8, Minibatch Loss: 2.0756, Training accuracy: 0.258\n",
      "Epoch: 10, Minibatch Loss: 2.0873, Training accuracy: 0.289\n",
      "Epoch: 12, Minibatch Loss: 1.9323, Training accuracy: 0.375\n",
      "Epoch: 14, Minibatch Loss: 1.7895, Training accuracy: 0.461\n",
      "Epoch: 16, Minibatch Loss: 1.7933, Training accuracy: 0.406\n",
      "Epoch: 18, Minibatch Loss: 1.6969, Training accuracy: 0.414\n",
      "Epoch: 20, Minibatch Loss: 1.5409, Training accuracy: 0.555\n",
      "Epoch: 22, Minibatch Loss: 1.5745, Training accuracy: 0.461\n",
      "Epoch: 24, Minibatch Loss: 1.4982, Training accuracy: 0.492\n",
      "Epoch: 26, Minibatch Loss: 1.4532, Training accuracy: 0.539\n",
      "Epoch: 28, Minibatch Loss: 1.3401, Training accuracy: 0.594\n",
      "Epoch: 30, Minibatch Loss: 1.3159, Training accuracy: 0.523\n",
      "Epoch: 32, Minibatch Loss: 1.1607, Training accuracy: 0.594\n",
      "Epoch: 34, Minibatch Loss: 1.1065, Training accuracy: 0.648\n",
      "Epoch: 36, Minibatch Loss: 1.0959, Training accuracy: 0.641\n",
      "Epoch: 38, Minibatch Loss: 1.0409, Training accuracy: 0.672\n",
      "Epoch: 40, Minibatch Loss: 0.9605, Training accuracy: 0.734\n",
      "Epoch: 42, Minibatch Loss: 0.7744, Training accuracy: 0.750\n",
      "Epoch: 44, Minibatch Loss: 0.8498, Training accuracy: 0.680\n",
      "Epoch: 46, Minibatch Loss: 0.8322, Training accuracy: 0.711\n",
      "Epoch: 48, Minibatch Loss: 0.6918, Training accuracy: 0.781\n",
      "Epoch: 50, Minibatch Loss: 0.7391, Training accuracy: 0.750\n",
      "Epoch: 52, Minibatch Loss: 0.7664, Training accuracy: 0.742\n",
      "Epoch: 54, Minibatch Loss: 0.7191, Training accuracy: 0.734\n",
      "Epoch: 56, Minibatch Loss: 0.6802, Training accuracy: 0.773\n",
      "Epoch: 58, Minibatch Loss: 0.7269, Training accuracy: 0.766\n",
      "Epoch: 60, Minibatch Loss: 0.5977, Training accuracy: 0.789\n",
      "Epoch: 62, Minibatch Loss: 0.5897, Training accuracy: 0.805\n",
      "Epoch: 64, Minibatch Loss: 0.5865, Training accuracy: 0.844\n",
      "Epoch: 66, Minibatch Loss: 0.7431, Training accuracy: 0.797\n",
      "Epoch: 68, Minibatch Loss: 0.7185, Training accuracy: 0.789\n",
      "Epoch: 70, Minibatch Loss: 0.6447, Training accuracy: 0.820\n",
      "Epoch: 72, Minibatch Loss: 0.7258, Training accuracy: 0.742\n",
      "Epoch: 74, Minibatch Loss: 0.5034, Training accuracy: 0.836\n",
      "Epoch: 76, Minibatch Loss: 0.5022, Training accuracy: 0.867\n",
      "Epoch: 78, Minibatch Loss: 0.4850, Training accuracy: 0.898\n",
      "Epoch: 80, Minibatch Loss: 0.5745, Training accuracy: 0.812\n",
      "Epoch: 82, Minibatch Loss: 0.5411, Training accuracy: 0.820\n",
      "Epoch: 84, Minibatch Loss: 0.6660, Training accuracy: 0.773\n",
      "Epoch: 86, Minibatch Loss: 0.5519, Training accuracy: 0.852\n",
      "Epoch: 88, Minibatch Loss: 0.5027, Training accuracy: 0.836\n",
      "Epoch: 90, Minibatch Loss: 0.6482, Training accuracy: 0.812\n",
      "Epoch: 92, Minibatch Loss: 0.4837, Training accuracy: 0.836\n",
      "Epoch: 94, Minibatch Loss: 0.4862, Training accuracy: 0.844\n",
      "Epoch: 96, Minibatch Loss: 0.4222, Training accuracy: 0.898\n",
      "Epoch: 98, Minibatch Loss: 0.3754, Training accuracy: 0.898\n",
      "Epoch: 100, Minibatch Loss: 0.3754, Training accuracy: 0.922\n",
      "Epoch: 102, Minibatch Loss: 0.4645, Training accuracy: 0.852\n",
      "Epoch: 104, Minibatch Loss: 0.2972, Training accuracy: 0.898\n",
      "Epoch: 106, Minibatch Loss: 0.5884, Training accuracy: 0.828\n",
      "Epoch: 108, Minibatch Loss: 0.4351, Training accuracy: 0.867\n",
      "Epoch: 110, Minibatch Loss: 0.5293, Training accuracy: 0.852\n",
      "Epoch: 112, Minibatch Loss: 0.4442, Training accuracy: 0.852\n",
      "Epoch: 114, Minibatch Loss: 0.3547, Training accuracy: 0.906\n",
      "Epoch: 116, Minibatch Loss: 0.5057, Training accuracy: 0.859\n",
      "Epoch: 118, Minibatch Loss: 0.4041, Training accuracy: 0.891\n",
      "Epoch: 120, Minibatch Loss: 0.4752, Training accuracy: 0.852\n",
      "Epoch: 122, Minibatch Loss: 0.5137, Training accuracy: 0.859\n",
      "Epoch: 124, Minibatch Loss: 0.3169, Training accuracy: 0.891\n",
      "Epoch: 126, Minibatch Loss: 0.3667, Training accuracy: 0.898\n",
      "Epoch: 128, Minibatch Loss: 0.2554, Training accuracy: 0.953\n",
      "Epoch: 130, Minibatch Loss: 0.3640, Training accuracy: 0.906\n",
      "Epoch: 132, Minibatch Loss: 0.2522, Training accuracy: 0.930\n",
      "Epoch: 134, Minibatch Loss: 0.2694, Training accuracy: 0.914\n",
      "Epoch: 136, Minibatch Loss: 0.3980, Training accuracy: 0.906\n",
      "Epoch: 138, Minibatch Loss: 0.3287, Training accuracy: 0.906\n",
      "Epoch: 140, Minibatch Loss: 0.4974, Training accuracy: 0.805\n",
      "Epoch: 142, Minibatch Loss: 0.2814, Training accuracy: 0.922\n",
      "Epoch: 144, Minibatch Loss: 0.2975, Training accuracy: 0.922\n",
      "Epoch: 146, Minibatch Loss: 0.2672, Training accuracy: 0.930\n",
      "Epoch: 148, Minibatch Loss: 0.4603, Training accuracy: 0.844\n",
      "Epoch: 150, Minibatch Loss: 0.2735, Training accuracy: 0.914\n",
      "Epoch: 152, Minibatch Loss: 0.3321, Training accuracy: 0.922\n",
      "Epoch: 154, Minibatch Loss: 0.2521, Training accuracy: 0.930\n",
      "Epoch: 156, Minibatch Loss: 0.3701, Training accuracy: 0.891\n",
      "Epoch: 158, Minibatch Loss: 0.2404, Training accuracy: 0.914\n",
      "Epoch: 160, Minibatch Loss: 0.4552, Training accuracy: 0.852\n",
      "Epoch: 162, Minibatch Loss: 0.2921, Training accuracy: 0.914\n",
      "Epoch: 164, Minibatch Loss: 0.3374, Training accuracy: 0.883\n",
      "Epoch: 166, Minibatch Loss: 0.3642, Training accuracy: 0.867\n",
      "Epoch: 168, Minibatch Loss: 0.2513, Training accuracy: 0.906\n",
      "Epoch: 170, Minibatch Loss: 0.2358, Training accuracy: 0.930\n",
      "Epoch: 172, Minibatch Loss: 0.4043, Training accuracy: 0.883\n",
      "Epoch: 174, Minibatch Loss: 0.2069, Training accuracy: 0.938\n",
      "Epoch: 176, Minibatch Loss: 0.2433, Training accuracy: 0.922\n",
      "Epoch: 178, Minibatch Loss: 0.3081, Training accuracy: 0.898\n",
      "Epoch: 180, Minibatch Loss: 0.2640, Training accuracy: 0.914\n",
      "Epoch: 182, Minibatch Loss: 0.2346, Training accuracy: 0.945\n",
      "Epoch: 184, Minibatch Loss: 0.2794, Training accuracy: 0.906\n",
      "Epoch: 186, Minibatch Loss: 0.4406, Training accuracy: 0.859\n",
      "Epoch: 188, Minibatch Loss: 0.3621, Training accuracy: 0.883\n",
      "Epoch: 190, Minibatch Loss: 0.2930, Training accuracy: 0.914\n",
      "Epoch: 192, Minibatch Loss: 0.2652, Training accuracy: 0.922\n",
      "Epoch: 194, Minibatch Loss: 0.4041, Training accuracy: 0.883\n",
      "Epoch: 196, Minibatch Loss: 0.2528, Training accuracy: 0.898\n",
      "Epoch: 198, Minibatch Loss: 0.2520, Training accuracy: 0.945\n",
      "Optimization Finished!\n",
      "Testing Accuracy:  0.9609\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(LOGDIR)\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    #print(batch_x.shape, batch_y.shape, keep_prob_val)\n",
    "    \n",
    "    if epoch%2==0:\n",
    "        loss, train_accuracy, s = sess.run([loss_op, accuracy, summ], feed_dict={x: batch_x, y: batch_y, keep_prob:keep_prob_val})\n",
    "        writer.add_summary(s, epoch)\n",
    "        print('Epoch: {}, Minibatch Loss: {:.4f}, Training accuracy: {:.3f}'.format(epoch, loss, train_accuracy))\n",
    "    \n",
    "    sess.run(train_step, feed_dict={x:batch_x, y:batch_y, keep_prob:keep_prob_val})\n",
    "\n",
    "print('Optimization Finished!')\n",
    "\n",
    "overall_accuracy = sess.run(accuracy, feed_dict={x:mnist.test.images, \n",
    "                                                     y:mnist.test.labels, \n",
    "                                                     keep_prob:1.0})    \n",
    "print(\"Testing Accuracy: \", overall_accuracy)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "path = 'C:/ASM/DevData/learning/tensorflow/cnn_model'\n",
    "create_directory(path)\n",
    "\n",
    "saver.save(sess, path+'/my-test-model')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/ASM/DevData/learning/tensorflow/cnn_model/my-test-model\n"
     ]
    }
   ],
   "source": [
    "path = 'C:/ASM/DevData/learning/tensorflow/cnn_model'\n",
    "sess = tf.Session()\n",
    "\n",
    "loader = tf.train.import_meta_graph(path+'/my-test-model.meta')\n",
    "loader.restore(sess, tf.train.latest_checkpoint(path))\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "x = graph.get_tensor_by_name('x:0')\n",
    "y = graph.get_tensor_by_name('y:0')\n",
    "keep_prob = graph.get_tensor_by_name('keep_prob:0')\n",
    "conv1_w = graph.get_tensor_by_name('conv_1/W:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[-1.96373597e-01  3.07093821e-02 -1.60170093e-01  3.28756459e-02\n",
      "    -4.01508249e-02  9.08037052e-02  5.01280762e-02 -3.70718315e-02\n",
      "    -7.69507214e-02 -2.06115142e-01  9.99956299e-03  1.82827469e-03\n",
      "     1.52269781e-01  1.68693021e-01 -2.21840143e-01 -2.34968984e-03\n",
      "    -4.58741896e-02  1.16128758e-01  1.65804505e-01  2.98357010e-02\n",
      "    -1.31330788e-01 -3.95340584e-02  8.55417028e-02  2.45654061e-02\n",
      "     1.39138931e-02 -2.94413026e-02  9.98105630e-02 -1.08950056e-01\n",
      "     6.98041022e-02  7.54759833e-02  5.07018566e-02 -1.10128699e-02]]\n",
      "\n",
      "  [[ 5.57864532e-02  5.27632236e-02 -1.17924534e-01 -5.67657389e-02\n",
      "     7.83004425e-03  1.26943395e-01 -8.63018483e-02 -1.12749584e-01\n",
      "    -8.83693025e-02 -1.85483605e-01  7.15756193e-02  1.93679720e-01\n",
      "    -2.36713178e-02 -3.90328728e-02 -5.61143719e-02  3.13711762e-02\n",
      "     1.64294496e-01  3.70246246e-02  1.30072743e-01 -6.63965791e-02\n",
      "     2.07225516e-01  4.33662049e-02 -3.98356430e-02  2.34195087e-02\n",
      "     1.84210297e-02 -1.86827719e-01  1.55888304e-01 -3.06522138e-02\n",
      "     6.05606427e-03  1.49405658e-01 -1.46641597e-01 -1.48007900e-01]]\n",
      "\n",
      "  [[-2.82001197e-02 -3.84382717e-02 -5.21734655e-02 -9.83440354e-02\n",
      "    -1.07778631e-01  8.67752433e-02  6.35086223e-02 -1.40401110e-01\n",
      "    -5.14240488e-02 -2.04016417e-01 -1.25001688e-02  1.34767130e-01\n",
      "     1.20493002e-01  7.59172961e-02  1.17524303e-01  7.59949237e-02\n",
      "     2.81055123e-02 -3.35094556e-02 -1.03789657e-01  4.64272909e-02\n",
      "    -3.98423262e-02  2.44807657e-02  7.33863413e-02 -3.85040045e-02\n",
      "     1.10068461e-02 -7.53142461e-02  1.24481417e-01 -1.71086922e-01\n",
      "    -5.42432861e-03 -2.36006528e-02 -3.32084857e-02 -9.99883749e-03]]\n",
      "\n",
      "  [[ 7.71299154e-02 -3.36597562e-02  7.88892880e-02 -1.75276101e-01\n",
      "     2.33866032e-02  5.69709316e-02  1.46736339e-01 -1.21822050e-02\n",
      "    -1.88852638e-01 -1.39981300e-01  1.46228433e-01 -3.02340221e-02\n",
      "     1.03489831e-01  6.28271028e-02  1.81823507e-01 -1.33970901e-02\n",
      "     8.00778642e-02 -1.28745914e-01 -4.87721106e-03 -5.20176208e-03\n",
      "     5.05787656e-02  7.91955143e-02  1.23135969e-01  9.73725989e-02\n",
      "     1.01689130e-01  5.53758480e-02  2.43593007e-02 -1.21874481e-01\n",
      "    -1.20841227e-01 -1.11783678e-02  1.57966077e-01  4.75382619e-02]]\n",
      "\n",
      "  [[ 7.51466900e-02 -2.08236482e-02 -6.95207939e-02 -8.93612728e-02\n",
      "     8.35181773e-02  8.52755159e-02  1.18315935e-01 -1.35756447e-03\n",
      "     4.94065229e-03 -1.03267513e-01  5.87989241e-02  9.04285982e-02\n",
      "     9.57731083e-02  4.25030924e-02  9.91217718e-02 -1.12652086e-01\n",
      "     7.71235004e-02 -1.45324260e-01 -1.41979098e-01  1.06076613e-01\n",
      "     1.03300549e-02  6.25929981e-02 -3.48364748e-02  2.13973317e-02\n",
      "     3.77931632e-02 -1.18901646e-02  1.39932498e-01 -5.91961332e-02\n",
      "    -5.35134338e-02  1.59663841e-01  1.48800671e-01  1.52451277e-01]]]\n",
      "\n",
      "\n",
      " [[[-9.87071842e-02 -2.25768667e-02  7.63813481e-02  1.64628786e-03\n",
      "     1.18131690e-01 -2.85464004e-02 -9.51734409e-02 -4.87112701e-02\n",
      "    -2.66434141e-02 -9.86457840e-02  1.16618499e-01 -8.18696711e-03\n",
      "    -4.72868830e-02  2.53739245e-02  5.35093509e-02 -6.61067590e-02\n",
      "     1.56873032e-01  1.04465738e-01  1.02285609e-01 -4.19602171e-02\n",
      "     1.96857005e-02  1.52683988e-01 -1.79793969e-01  1.13263503e-02\n",
      "    -2.38798279e-02 -5.51076196e-02  1.24181442e-01  1.56334713e-01\n",
      "    -4.15279120e-02  1.11926310e-02  6.44311309e-02 -3.39324139e-02]]\n",
      "\n",
      "  [[ 1.62921980e-01  4.15304378e-02 -9.71651636e-03 -4.67656367e-03\n",
      "     1.19633183e-01  1.76764295e-01  7.24938884e-02 -1.59275681e-01\n",
      "    -5.09115402e-03  1.09992117e-01  7.89787099e-02 -5.80708757e-02\n",
      "    -1.01918027e-01  1.04047634e-01  1.28372118e-01  4.33223769e-02\n",
      "    -1.82158351e-01 -5.80355674e-02 -2.81314589e-02  6.79950714e-02\n",
      "     8.57802331e-02  1.35450184e-01 -1.29271194e-01  8.02687705e-02\n",
      "    -1.66443211e-03  2.81051025e-02  1.04981087e-01 -9.99932885e-02\n",
      "    -1.23687975e-01  4.40245084e-02  7.09793940e-02  1.10625908e-01]]\n",
      "\n",
      "  [[-7.67375305e-02  5.22025526e-02  1.12337612e-01  9.12616625e-02\n",
      "     4.09101360e-02  5.58231026e-02  1.07752003e-01 -4.47619557e-02\n",
      "    -1.32079020e-01 -1.46688759e-01  2.10149940e-02  1.72607824e-02\n",
      "     9.26905200e-02  1.45720288e-01  6.45743459e-02 -7.77849182e-02\n",
      "    -1.14592977e-01 -3.14704180e-02 -1.64057195e-01  8.09906572e-02\n",
      "    -1.21307897e-03 -1.14703864e-01 -1.54857235e-02 -6.94910064e-02\n",
      "    -1.09058753e-01  9.98654142e-02 -5.23961261e-02 -3.00191715e-02\n",
      "     1.11510463e-01  1.13821909e-01  1.66902952e-02  2.08814573e-02]]\n",
      "\n",
      "  [[ 5.82447974e-03  7.03703910e-02  5.66966943e-02 -1.43123865e-01\n",
      "    -2.56678369e-02  1.03507042e-02  1.94210932e-02 -3.29730362e-02\n",
      "     1.32742256e-01  9.59841814e-03  7.81210721e-04 -6.73406348e-02\n",
      "     8.32490548e-02  1.25898838e-01  1.41351044e-01  2.16367319e-02\n",
      "     1.01359226e-02 -8.13078657e-02  4.18228321e-02  2.75290739e-02\n",
      "     5.60852475e-02 -1.11917838e-01  3.68868746e-02 -1.42375575e-02\n",
      "     6.00007689e-03 -8.05062056e-02  1.15772620e-01 -1.26276135e-01\n",
      "    -1.13913439e-01 -4.86967014e-03 -8.74739699e-03  5.12436144e-02]]\n",
      "\n",
      "  [[ 6.52776584e-02 -3.62155400e-02  1.07020006e-01 -1.36801051e-02\n",
      "     1.03980996e-01  6.17262088e-02 -3.35850939e-02  3.94182950e-02\n",
      "     6.19772598e-02 -2.04985738e-02 -5.08299060e-02 -1.12402074e-01\n",
      "    -9.71024334e-02 -1.00358754e-01 -1.08656250e-02  1.08176433e-01\n",
      "    -1.59962967e-01 -9.94106829e-02 -5.37755005e-02  1.81193247e-01\n",
      "     1.08158126e-01  1.68973133e-02  1.24784328e-01 -1.42385527e-01\n",
      "     1.74563304e-02 -1.13414161e-01 -1.65756755e-02 -2.56118998e-02\n",
      "    -5.81642687e-02  1.80035666e-01  1.44730434e-01  8.21888670e-02]]]\n",
      "\n",
      "\n",
      " [[[ 1.53437527e-02 -4.80884612e-02  1.58288404e-01  7.00637773e-02\n",
      "     5.09330481e-02  6.98959008e-02  1.46460757e-01 -6.92954808e-02\n",
      "    -2.88372450e-02  8.99675265e-02  1.19853310e-01 -1.53144225e-01\n",
      "    -2.60879118e-02 -2.02629983e-01  6.83623925e-02  1.14466146e-01\n",
      "    -2.22870424e-01  9.62838754e-02  1.79048777e-01  1.73322521e-02\n",
      "     6.12613596e-02  2.99716648e-02 -1.34269834e-01  1.49584711e-01\n",
      "    -1.98927164e-01  1.25533849e-01 -8.37841332e-02 -1.64001599e-01\n",
      "     6.86644614e-02  1.57092586e-02  1.03348158e-02  2.03526407e-01]]\n",
      "\n",
      "  [[-2.68869195e-02 -7.98731223e-02  9.56274197e-02  2.69761379e-03\n",
      "    -1.08697778e-02  3.51367053e-03  7.92455673e-02 -2.26374958e-02\n",
      "    -1.19628362e-01 -9.77688655e-02 -9.72600505e-02 -7.96258897e-02\n",
      "     1.09802990e-04 -7.28710368e-02  2.77381856e-02 -1.11512356e-01\n",
      "    -7.69674107e-02 -5.77819999e-03  1.23752847e-01  1.98366806e-01\n",
      "    -1.48983346e-02 -7.32377470e-02 -1.12182714e-01  1.73173025e-01\n",
      "    -1.67994350e-01 -1.57270998e-01 -4.53678742e-02  3.45435441e-02\n",
      "     1.09146601e-02 -5.62860630e-02  3.47345658e-02  1.19420901e-01]]\n",
      "\n",
      "  [[ 3.16091627e-02 -1.05011344e-01  1.39770120e-01 -1.44589499e-01\n",
      "     5.83196990e-02 -3.52613851e-02 -1.19330250e-01  2.59486702e-03\n",
      "    -2.33185753e-01 -4.38578892e-03  3.06478571e-02 -1.01319119e-01\n",
      "     1.77294672e-01 -1.94326431e-01  9.35479924e-02 -1.24758527e-01\n",
      "     2.01781988e-02  5.46006635e-02 -8.08201060e-02  7.33180717e-02\n",
      "    -7.52035230e-02  4.72895131e-02  7.98689052e-02  1.79243177e-01\n",
      "    -1.64158747e-01 -1.95350856e-01 -4.93340604e-02  4.91559543e-02\n",
      "    -6.45211637e-02  4.99758264e-03 -9.67000052e-02  2.71504447e-02]]\n",
      "\n",
      "  [[-2.13598274e-02 -2.02108115e-01 -1.64382122e-02 -8.37451033e-03\n",
      "    -7.13575706e-02 -5.45755327e-02  1.98466927e-02  7.71879032e-02\n",
      "    -4.89738509e-02 -6.07240684e-02 -7.24750981e-02 -9.00044739e-02\n",
      "    -1.78069696e-01 -9.93206128e-02 -1.05420791e-01  2.00686723e-01\n",
      "     1.05530813e-01 -1.27865732e-01 -1.38569772e-01 -1.07214004e-02\n",
      "     5.86365238e-02  6.67427704e-02  1.92680746e-01 -1.93359494e-01\n",
      "    -1.10625371e-01  5.72993197e-02  1.50793223e-02 -7.53476545e-02\n",
      "     6.32296354e-02  3.12814042e-02 -1.63852647e-01  1.48167051e-02]]\n",
      "\n",
      "  [[-1.52969718e-01 -1.03278747e-02  6.35668859e-02 -2.13284399e-02\n",
      "    -3.83545756e-02  8.14071521e-02  3.28148492e-02  1.29305506e-02\n",
      "    -5.38798841e-03  1.51358778e-02  1.30235359e-01 -1.51048094e-01\n",
      "    -2.01179117e-01  7.70108402e-02 -2.63660233e-02  1.29010603e-01\n",
      "     2.60164943e-02 -1.26529276e-01 -1.89101145e-01  1.27234876e-01\n",
      "    -1.95393637e-01 -1.28942847e-01  8.72012824e-02 -9.88679007e-02\n",
      "    -1.75617144e-01 -1.26800492e-01  9.09284204e-02 -1.69390798e-01\n",
      "    -1.39879122e-01  4.03722860e-02 -1.50213376e-01 -1.13391802e-01]]]\n",
      "\n",
      "\n",
      " [[[-2.48480737e-02 -8.13304707e-02  7.90497754e-03  9.57001075e-02\n",
      "     4.57826583e-03 -1.15493678e-01  3.98353338e-02  2.44422648e-02\n",
      "    -7.78791532e-02 -8.50265473e-02 -1.20114880e-02 -2.77805440e-02\n",
      "     6.48964420e-02 -1.90571360e-02 -2.07649786e-02 -9.47364569e-02\n",
      "     1.94172133e-02 -5.98512888e-02 -5.47729582e-02 -1.80384412e-01\n",
      "     4.14330978e-03  1.31801054e-01  8.95208865e-03  4.56061177e-02\n",
      "     6.35680482e-02 -1.29035767e-02 -2.48352326e-02  1.54012457e-01\n",
      "    -1.21591263e-01 -8.04915577e-02  1.97524624e-03  1.47681445e-01]]\n",
      "\n",
      "  [[ 1.39614671e-01 -8.69787261e-02 -3.43837850e-02 -6.37930110e-02\n",
      "     6.14454076e-02 -2.38292783e-01  4.44527492e-02  3.81126031e-02\n",
      "     1.08851744e-02  2.38685329e-02 -5.34341000e-02 -2.17625067e-01\n",
      "     1.16548799e-01 -1.21436983e-01  1.86971813e-01  5.27627617e-02\n",
      "    -1.30491003e-01  1.21604308e-01 -1.01952575e-01 -1.56921476e-01\n",
      "    -1.44426785e-02  1.60187513e-01  1.38779497e-02  5.88092543e-02\n",
      "     2.57464107e-02 -4.44355682e-02  5.66610880e-03 -2.08200491e-03\n",
      "    -3.65516916e-03 -1.55232131e-01 -2.29549110e-01  1.82466164e-01]]\n",
      "\n",
      "  [[-5.41438572e-02 -8.99417773e-02  2.50537414e-04 -5.55803590e-02\n",
      "    -1.73431647e-03  1.15231290e-01  5.31131588e-02 -8.68262053e-02\n",
      "    -6.65397868e-02  1.16404310e-01  1.41742388e-02  9.81835555e-03\n",
      "    -3.56210098e-02 -3.37507315e-02  4.50093150e-02  2.26046503e-01\n",
      "    -2.51459633e-03 -2.42746532e-01  1.15692727e-01  7.22535998e-02\n",
      "    -3.22415940e-02  8.26040357e-02  3.43591236e-02  9.54044461e-02\n",
      "    -6.16417080e-02  2.51894314e-02 -1.09571710e-01  2.01137424e-01\n",
      "    -6.05771616e-02 -6.28057718e-02  6.22430518e-02 -2.22151307e-03]]\n",
      "\n",
      "  [[ 3.92513461e-02  1.67528898e-01  8.02231431e-02 -3.77122313e-02\n",
      "     1.52457595e-01  1.98751271e-01  1.28085196e-01 -2.55447030e-02\n",
      "    -9.67070609e-02  8.05071462e-03  1.02382623e-01 -7.36428499e-02\n",
      "    -3.85299176e-02 -3.52912247e-02  7.48858750e-02 -1.57774724e-02\n",
      "     8.87854844e-02 -1.35414079e-01 -3.19867046e-03 -2.44273208e-02\n",
      "    -3.60860396e-03  3.10060177e-02  2.48803478e-02 -1.01674892e-01\n",
      "    -2.11433545e-02  6.28169253e-03 -1.76719248e-01  8.51646587e-02\n",
      "     2.17254050e-02  8.72504488e-02  1.77500155e-02 -4.18060459e-02]]\n",
      "\n",
      "  [[ 2.91326661e-02 -1.95441153e-02  1.97691068e-01 -1.71432272e-01\n",
      "    -1.74657404e-02  1.47340715e-01 -1.16891250e-01  4.70450940e-03\n",
      "     1.80889979e-01  1.11839548e-02 -7.34103248e-02 -2.33093910e-02\n",
      "     6.03021309e-02 -8.52977112e-02  3.09296660e-02 -3.93941440e-02\n",
      "     6.37719333e-02  4.70468216e-02 -1.44987568e-01  4.56764624e-02\n",
      "    -8.46578851e-02 -3.74226309e-02 -9.68954414e-02  1.07335143e-01\n",
      "     1.34465154e-02 -4.60225437e-03 -4.76250313e-02 -1.21444881e-01\n",
      "     7.67350383e-03 -1.46613643e-01 -4.09086719e-02 -7.08241984e-02]]]\n",
      "\n",
      "\n",
      " [[[ 6.83669671e-02  4.90111262e-02 -2.51019090e-01  1.58454478e-01\n",
      "    -6.36827424e-02 -1.55111089e-01 -8.98704156e-02  1.36727616e-01\n",
      "    -6.19235681e-03  1.36915505e-01 -1.53984427e-01 -1.62310675e-01\n",
      "    -7.19439238e-02  1.97207015e-02  3.83676775e-03  2.72755623e-02\n",
      "     5.70042478e-03 -9.92508791e-03  6.48891479e-02 -1.20946243e-01\n",
      "     5.83330579e-02  1.75837636e-01 -9.00320858e-02 -3.54914293e-02\n",
      "    -1.02654472e-01 -4.66847159e-02  9.19661894e-02 -1.43078268e-01\n",
      "     3.98725867e-02  5.57127148e-02  2.55099423e-02 -3.43755893e-02]]\n",
      "\n",
      "  [[-5.01933731e-02 -7.14769065e-02 -1.37456015e-01 -8.21482688e-02\n",
      "    -1.02724992e-02 -7.58613348e-02 -7.92587176e-02  1.34989917e-01\n",
      "     1.77348331e-01  6.45456091e-02  9.93133485e-02 -2.02755281e-03\n",
      "     8.36992450e-03 -3.78997810e-02 -2.15665456e-02 -1.21625379e-01\n",
      "     1.11852139e-01 -1.50902554e-01 -2.62709670e-02  5.76329529e-02\n",
      "    -3.43729672e-03 -1.32072875e-02  1.03784747e-01  2.10692771e-02\n",
      "     5.95252104e-02  2.40788553e-02 -1.11179359e-01 -1.84874739e-02\n",
      "    -1.62310768e-02 -1.31421283e-01 -8.89959186e-02 -1.08499140e-01]]\n",
      "\n",
      "  [[ 2.43507754e-02 -1.21773019e-01 -2.01868609e-01 -1.45093156e-02\n",
      "    -1.31174386e-01 -5.66793010e-02 -2.05379389e-02 -2.15057321e-02\n",
      "    -1.73019245e-01  1.85947865e-01  9.46348608e-02  1.37923911e-01\n",
      "    -1.04712479e-01 -7.82952085e-02  2.19514947e-02  9.84598994e-02\n",
      "     7.58292153e-02 -2.28946611e-01 -1.13794252e-01  6.91369399e-02\n",
      "    -6.53448179e-02  5.27712107e-02  1.08274028e-01  6.64894357e-02\n",
      "     8.34876522e-02 -6.84309378e-02 -6.38925061e-02  1.43602163e-01\n",
      "    -7.70609006e-02 -8.28774553e-03 -1.90567464e-01  9.45913941e-02]]\n",
      "\n",
      "  [[-1.57139942e-01  6.98694214e-02 -1.24149434e-01 -4.66395058e-02\n",
      "    -9.64973196e-02  3.44693214e-02 -8.75827949e-03  2.14289408e-02\n",
      "     3.72322761e-02 -9.66433883e-02  3.51340175e-02 -1.44426644e-01\n",
      "    -2.08961102e-03 -5.69538288e-02 -1.71546221e-01  5.12451455e-02\n",
      "    -2.39894167e-02 -1.09591382e-02  4.44248654e-02 -1.25272974e-01\n",
      "     3.72884199e-02 -1.78358078e-01  1.08641811e-01 -7.60464445e-02\n",
      "    -2.42966507e-02 -1.23804137e-02 -2.44396850e-02  7.91417062e-02\n",
      "     1.16338298e-01  1.18027844e-01 -5.53228296e-02  2.23126393e-02]]\n",
      "\n",
      "  [[-1.55984104e-01 -6.88725859e-02 -6.98503032e-02  6.33324832e-02\n",
      "    -1.70075357e-01 -7.60462880e-02  1.62001655e-01 -1.70491979e-01\n",
      "     1.23394497e-01  4.17832807e-02  1.62949622e-01 -5.60682006e-02\n",
      "    -2.84422040e-02 -7.43161514e-02  1.25584230e-01  6.13699444e-02\n",
      "     7.91264977e-03  1.35120317e-01 -4.91584912e-02  8.00524577e-02\n",
      "     5.69518991e-02 -1.50636002e-01 -1.38390526e-01 -5.67000881e-02\n",
      "    -6.22270182e-02  4.36709411e-02 -1.26213461e-01  3.54760811e-02\n",
      "    -7.76938051e-02  9.51332673e-02 -1.14193164e-01  5.05927280e-02]]]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(conv1_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = graph.get_tensor_by_name('accuracy:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_accuracy = sess.run(accuracy, feed_dict={x:mnist.test.images, \n",
    "                                                     y:mnist.test.labels, \n",
    "                                                     keep_prob:1.0})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.9609\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy: \", overall_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
