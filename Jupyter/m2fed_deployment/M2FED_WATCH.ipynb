{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import time\n",
    "from keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    directory = os.path.dirname(path)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        print(\"Directory created: \", directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def milli_to_str(t):\n",
    "    t = int(t/1000)\n",
    "    s = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(t))\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_folder = \"C:/xampp/htdocs/m2fed_watch/uploads/\"\n",
    "dest_folder_root = \"M2FED_Results/\"\n",
    "\n",
    "dest_folders = {}\n",
    "dest_folders[\"rawdata\"] = dest_folder_root+\"RawData/M2FED_Watch_Data/\"\n",
    "dest_folders[\"rawdata_error\"] = dest_folder_root+\"RawData/M2FED_Watch_Data/error_files/\"\n",
    "dest_folders[\"battery\"] = dest_folder_root+\"Eating/battery/\"\n",
    "dest_folders[\"beacon\"] = dest_folder_root+\"Eating/beacon/\"\n",
    "dest_folders[\"bite\"] = dest_folder_root+\"Eating/bite/\"\n",
    "dest_folders[\"ema\"] = dest_folder_root+\"Eating/ema/\"\n",
    "dest_folders[\"location\"] = dest_folder_root+\"Eating/location/\"\n",
    "dest_folders[\"log\"] = dest_folder_root+\"Eating/log/\"\n",
    "dest_folders[\"meal\"] = dest_folder_root+\"Eating/meal/\"\n",
    "\n",
    "dest_folders[\"battery_readable\"] = dest_folder_root+\"Eating_readable/battery/\"\n",
    "dest_folders[\"beacon_readable\"] = dest_folder_root+\"Eating_readable/beacon/\"\n",
    "dest_folders[\"bite_readable\"] = dest_folder_root+\"Eating_readable/bite/\"\n",
    "dest_folders[\"ema_readable\"] = dest_folder_root+\"Eating_readable/ema/\"\n",
    "dest_folders[\"location_readable\"] = dest_folder_root+\"Eating_readable/location/\"\n",
    "dest_folders[\"log_readable\"] = dest_folder_root+\"Eating_readable/log/\"\n",
    "dest_folders[\"meal_readable\"] = dest_folder_root+\"Eating_readable/meal/\"\n",
    "\n",
    "if not os.path.exists(os.path.dirname(source_folder)):\n",
    "    print(\"Source folder doesn't exist. Program exited.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "for key, value in dest_folders.items():\n",
    "    create_directory(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_date_str = \"\"\n",
    "window_len_half = 48\n",
    "window_len = 2 * window_len_half\n",
    "interval = 1000/16  #in millisecond\n",
    "smooth_factor = 0.8\n",
    "\n",
    "x_th_max = -3\n",
    "min_bite_interval = 40 #samples\n",
    "var_th = 1\n",
    "\n",
    "min_meal_process_interval = 30*100 #milliseconds\n",
    "min_ema_sent_interval = 10*60*1000 #milliseconds\n",
    "meal_bite_max_distance = 60*1000 #milli second\n",
    "min_meal_duration = 60*1000 #milliseconds\n",
    "min_meal_bite_count = 3\n",
    "min_wait_time_after_meal_to_decide = 4*60*1000 #milliseconds\n",
    "\n",
    "last_sensor_files = {}\n",
    "bite_buffer = {}\n",
    "meal_buffer = {}\n",
    "last_meal_process_time = {}\n",
    "last_time_ema_sent = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"eating_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_beacon_data(data, file_info):\n",
    "    watch_id = file_info[\"watch_id\"]    \n",
    "    last_beacon_time = 0\n",
    "    last_battery_time = 0\n",
    "    last_battery_pct = \"\"    \n",
    "    beacon_data = \"\"\n",
    "    battery_data =\"\"\n",
    "    beacon_data_count = 0\n",
    "    battery_data_count = 0\n",
    "    \n",
    "    for s in data:\n",
    "        tokens = s.rstrip().split(\",\")\n",
    "        t = int(tokens[0]) + file_info[\"reference_time_diff\"]\n",
    "        code = int(tokens[1])\n",
    "        mac = tokens[2]\n",
    "        if code == 1:            \n",
    "            tx_power = tokens[3]\n",
    "            rssi = tokens[4]\n",
    "            beacon_data += mac + \",\" + watch_id +\",\" + str(t) +\",\"+ tx_power +\",\" + rssi +\"\\n\"\n",
    "            beacon_data_count += 1\n",
    "            last_beacon_time = t           \n",
    "            \n",
    "        elif code > 1 and code < 1000:            \n",
    "            battery_pct = tokens[3]\n",
    "            battery_data += str(t) +\",\" + str(code) + \",\" + mac + \",\" + battery_pct +\"\\n\"            \n",
    "            last_battery_time = t\n",
    "            last_battery_pct = battery_pct\n",
    "            battery_data_count += 1\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Error in ble file code\")\n",
    "            \n",
    "    if len(beacon_data)>0:\n",
    "        tm = datetime.fromtimestamp(last_beacon_time/1000.0)\n",
    "        print(\"Beacon reading count:\", beacon_data_count, \", Last reading at: \", tm)\n",
    "        with open(dest_folders[\"beacon\"]+to_date_str+\"_beacon_data_\"+ watch_id, \"a\") as file:\n",
    "            file.write(beacon_data)\n",
    "            \n",
    "    if len(battery_data)>0:\n",
    "        tm = datetime.fromtimestamp(last_battery_time/1000.0)\n",
    "        print(\"Battery reading count:\", battery_data_count ,\", Last reading at: \", tm, \", Pct: \", last_battery_pct)\n",
    "        with open(dest_folders[\"battery\"]+to_date_str+\"_watch_battery_\"+ watch_id, \"a\") as file:\n",
    "            file.write(battery_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_sensor_data(data, file_info):    \n",
    "    global last_sensor_file\n",
    "    global bite_buffer\n",
    "    global meal_buffer\n",
    "    global last_meal_process_time\n",
    "    global last_time_ema_sent\n",
    "    watch_id = file_info[\"watch_id\"]\n",
    "    \n",
    "    print(\"Sample size: \", data.shape)\n",
    "    #print(file_info[\"reference_time_diff\"])\n",
    "    #print(data[:10, :])    \n",
    "    data[:, 0] = data[:, 0] + file_info[\"reference_time_diff\"]    \n",
    "    print(\"Start, end: \", datetime.fromtimestamp(data[0, 0]/1000), \", \", datetime.fromtimestamp(data[-1, 0]/1000), \", Duration(sec): \", ((data[-1, 0]-data[0, 0])/1000))\n",
    "    \n",
    "    bite_str = \"\"    \n",
    "    last_data = []\n",
    "    resample_start_time = data[0, 0]\n",
    "    last_smooth_sample = data[0, :]    \n",
    "    \n",
    "    if watch_id in last_sensor_files:\n",
    "        last_file = last_sensor_files[watch_id]        \n",
    "        if last_file[\"service_start_time_watch\"] == file_info[\"service_start_time_watch\"] and last_file[\"file_index\"] == file_info[\"file_index\"] -1:\n",
    "            print(\"This is sequence of last file.\")            \n",
    "            last_data = last_file[\"data_resampled\"]\n",
    "            data = np.concatenate((last_file[\"last_sample_raw\"], data))\n",
    "            resample_start_time = last_data[-1, 0] + interval\n",
    "            last_smooth_sample = last_data[-1, :]\n",
    "    else:\n",
    "        bite_buffer[watch_id] = []\n",
    "        meal_buffer[watch_id] = []        \n",
    "        last_meal_process_time[watch_id] = 0\n",
    "        last_time_ema_sent[watch_id] = 0\n",
    "    \n",
    "    #resample data    \n",
    "    ts = np.arange(resample_start_time, data[-1, 0], interval)\n",
    "    count = len(ts)\n",
    "    resdata = np.zeros((count, 4))  #resampled data  \n",
    "    j = 0\n",
    "    for i in range(count):                        \n",
    "        while not(data[j, 0] <= ts[i] < data[j+1, 0]):\n",
    "            j+=1        \n",
    "        resdata[i, 0] = ts[i]\n",
    "        factor = (ts[i] - data[j, 0])/(data[j+1, 0]-data[j, 0]);\n",
    "        resdata[i, 1:] = (1-factor)*data[j, 1:]  + factor*data[j+1, 1:]\n",
    "    \n",
    "    print(\"Sample size after resampling: \", resdata.shape)\n",
    "    \n",
    "    #smooth data\n",
    "    last_smooth_sample = last_smooth_sample.reshape((1, 4))\n",
    "    resdata[0, 1:] = smooth_factor*last_smooth_sample[0, 1:] + (1-smooth_factor)*resdata[0, 1:]\n",
    "    for i in range(1, count):\n",
    "        resdata[i, 1:] = smooth_factor*resdata[i-1, 1:] + (1-smooth_factor)*resdata[i, 1:] \n",
    "      \n",
    "    \n",
    "    #concatening data from last file\n",
    "    if len(last_data)>0:\n",
    "        resdata = np.concatenate((last_data[-window_len:, :], resdata))\n",
    "    \n",
    "    print(\"Sample size after concatenate: \", resdata.shape)\n",
    "        \n",
    "    #finding potential bite points by x_th\n",
    "    step_length = min_bite_interval//2\n",
    "    x = resdata[:, 1]\n",
    "    count = len(x)\n",
    "    mp = []\n",
    "    for i in range(0, count-step_length, step_length):\n",
    "        min_index = i\n",
    "        for j in range(i, i+step_length):\n",
    "            if x[j] < x[min_index]:\n",
    "                min_index = j\n",
    "                \n",
    "        if x[min_index] <= x_th_max and min_index >= window_len_half and min_index < count-window_len_half:\n",
    "            mp.append(min_index)\n",
    "    \n",
    "    print(\"mp count by x_th: \", len(mp), \" >>\", mp)\n",
    "    \n",
    "    \n",
    "    #filtering potential bite points by neighbor distance\n",
    "    while len(mp)>=2:\n",
    "        res = []            \n",
    "        ix = mp[0]\n",
    "        ixRight = mp[1]\n",
    "        if ixRight - ix > min_bite_interval or x[ix] < x[ixRight]:\n",
    "            res.append(ix)\n",
    "\n",
    "        mp_count = len(mp)\n",
    "        for i in range(1, mp_count - 1):\n",
    "            ix = mp[i]\n",
    "            ixLeft = mp[i - 1]\n",
    "            ixRight = mp[i + 1]\n",
    "\n",
    "            cond_left = ix - ixLeft > min_bite_interval or x[ix] <= x[ixLeft]\n",
    "            cond_right = ixRight - ix > min_bite_interval or x[ix] < x[ixRight]\n",
    "            if cond_left and cond_right:\n",
    "                res.append(ix)\n",
    "\n",
    "        ix = mp[mp_count - 1]\n",
    "        ixLeft = mp[mp_count - 2]\n",
    "        if ix - ixLeft > min_bite_interval or x[ix] <= x[ixLeft]:\n",
    "            res.append(ix)            \n",
    "\n",
    "        if len(mp) == len(res):\n",
    "            break        \n",
    "        mp = res \n",
    "            \n",
    "    print(\"mp count after neighbor filter:\", len(mp), \" >>\", mp)    \n",
    "    \n",
    "    #filtering potential bite points by features\n",
    "    mp_count = len(mp)\n",
    "    if mp_count>0:\n",
    "        res = []        \n",
    "        for i in range(mp_count):\n",
    "            ix = mp[i]\n",
    "            v = np.sum(np.var(resdata[ix-window_len_half:ix+window_len_half, 1:], axis = 0))\n",
    "            if v >= var_th:\n",
    "                res.append(ix)\n",
    "        mp = res        \n",
    "    \n",
    "    print(\"mp count after feature filter:\", len(mp), \" >>\", mp)\n",
    "    \n",
    "    #extracting and normalizing segments\n",
    "    bites = []\n",
    "    mp_count = len(mp)\n",
    "    if mp_count>0:\n",
    "        X = np.zeros((mp_count, window_len, 3))\n",
    "        for i in range(mp_count):\n",
    "            ix = mp[i]\n",
    "            d = resdata[ix-window_len_half:ix+window_len_half, 1:]\n",
    "            sq = np.multiply(d, d)\n",
    "            mag = np.sqrt(np.sum(sq, axis = 1, keepdims=True))\n",
    "            X[i, :, :] = np.divide(d, mag)\n",
    "                \n",
    "        #predicting bites\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "        Ypr = model.predict(X, verbose=0)        \n",
    "        for i in range(mp_count):\n",
    "            if Ypr[i, 0]>=0.5:\n",
    "                ix = mp[i]\n",
    "                bites.append([resdata[ix, 0], Ypr[i, 0]])                \n",
    "                bite_str += watch_id + \",\" + milli_to_str(file_info[\"upload_time\"]) + \",\" + milli_to_str(int(resdata[ix, 0])) + \",0,\" + str(Ypr[i, 0])+\"\\n\"\n",
    "    \n",
    "    print(\"Bite count: \", len(bites))\n",
    "    #print(bite_buffer)\n",
    "    if len(bites)>0:            \n",
    "        bite_buffer[watch_id].extend(bites)\n",
    "        print(bite_str)\n",
    "        with open(dest_folders[\"bite\"]+to_date_str+\"_eating_bite_\"+ watch_id, \"a\") as file:\n",
    "            file.write(bite_str) \n",
    "    \n",
    "    #storing info and data for next iteration\n",
    "    file_info[\"last_sample_raw\"] = data[-1, :].reshape(1, 4)\n",
    "    file_info[\"data_resampled\"] = resdata\n",
    "    last_sensor_files[watch_id] = file_info\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_meals_ema(watch_id):\n",
    "    global bite_buffer\n",
    "    global meal_buffer\n",
    "    global last_meal_process_time\n",
    "    global last_time_ema_sent\n",
    "    \n",
    "    cur_time = int(time.time()*1000)\n",
    "    bite_buff = bite_buffer[watch_id]\n",
    "    if len(bite_buff) < min_meal_bite_count or cur_time - last_meal_process_time[watch_id]< min_meal_process_interval or cur_time - last_time_ema_sent[watch_id] < min_ema_sent_interval:\n",
    "        return\n",
    "        \n",
    "    meal_str = \"\"\n",
    "    ema_str = \"\"\n",
    "    \n",
    "    \n",
    "    last_meal_process_time[watch_id] = cur_time\n",
    "    clusters = []\n",
    "    c = []\n",
    "    c.append(bite_buff[0])\n",
    "    for i in range(1, len(bite_buff)):\n",
    "        if bite_buff[i][0] - bite_buff[i-1][0] <= meal_bite_max_distance:\n",
    "            c.append(bite_buff[i])\n",
    "        else:\n",
    "            if len(c) >= min_meal_bite_count:\n",
    "                clusters.append(c)\n",
    "            c = []\n",
    "            c.append(bite_buff[i])\n",
    "            \n",
    "\n",
    "    if len(c) >= min_meal_bite_count:\n",
    "        clusters.append(c)\n",
    "\n",
    "    #print(clusters)\n",
    "    if len(clusters) > 0:            \n",
    "        for i in range(len(clusters)-1):\n",
    "            c = clusters[i]\n",
    "            meal_str += watch_id +\",\"+ str(cur_time) +\",\"+ str(c[0][0]) +\",\"+ str(c[-1][0]) +\",\"+ str(len(c)) +\"\\n\"\n",
    "\n",
    "\n",
    "        c = clusters[-1]\n",
    "        last_time_for_remove = c[0][0]-1        \n",
    "        if cur_time - c[-1][0] >= min_wait_time_after_meal_to_decide and c[-1][0] - c[0][0] >= min_meal_duration and len(c)>=min_meal_bite_count:\n",
    "            meal_str += watch_id +\",\"+ str(cur_time) +\",\"+ str(c[0][0]) +\",\"+ str(c[-1][0]) +\",\"+ str(len(c)) +\"\\n\"            \n",
    "            last_time_for_remove = c[-1][0]\n",
    "            \n",
    "            if (cur_time - c[-1][0]) <= 30*60*1000:\n",
    "                last_time_ema_sent\n",
    "                ema_str = watch_id + \",\" + last_time_ema_sent + \",\" + last_time_ema_sent +\",0\\n\"\n",
    "        \n",
    "        new_buff=[]\n",
    "        for i in range(len(bite_buff)):\n",
    "            if bite_buff[i][0] > last_time_for_remove:\n",
    "                new_buff.append(bite_buff[i])\n",
    "            \n",
    "        bite_buffer[watch_id] = bite_buff\n",
    "                \n",
    "    if len(meal_str)>0:\n",
    "        with open(dest_folders[\"meal\"]+to_date_str+\"_eating_meal_\"+ watch_id, \"a\") as file:\n",
    "            file.write(meal_str) \n",
    "            \n",
    "    if len(ema_str)>0:\n",
    "        with open(dest_folders[\"ema\"]+to_date_str+\"_eating_ema_\"+ watch_id, \"a\") as file:\n",
    "            file.write(ema_str) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"****************************************************\")\n",
    "print(\"****** WELCOME TO M2FED WATCH DATA PROCESSOR  ******\")\n",
    "print(\"****************************************************\")\n",
    "\n",
    "sleep_count = 0\n",
    "while True:    \n",
    "    file_list = os.listdir(source_folder)\n",
    "    if len(file_list) ==0:\n",
    "        for key, _ in meal_buffer.items():\n",
    "            process_meals_ema(key)\n",
    "        sleep_count += 1\n",
    "        cur_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(\"Waiting for data. Last checked at: %s\"%cur_time, end=\"\\r\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "              \n",
    "    to_date_str = datetime.now().strftime(\"%Y-%m-%d\")        \n",
    "    last_process_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    print(\"\\n\\n----------------------------------------------------\")\n",
    "    print(\"Processing at time:\", last_process_time, \", File count: \", len(file_list))        \n",
    "    \n",
    "    file_list.sort()\n",
    "    for f in file_list:\n",
    "        print(\"\\nProcessing file: \", f)        \n",
    "        tokens = f.rstrip().split(\"-\")\n",
    "        \n",
    "        try:\n",
    "            if len(tokens)!=7:\n",
    "                raise Exception(\"File name do not have 7 tokens. It has \", len(tokens), \" tokens!\")\n",
    "\n",
    "            file_type = tokens[0]\n",
    "            file_info = {}        \n",
    "            file_info[\"watch_id\"] = tokens[1]\n",
    "            file_info[\"reference_time_server\"] = int(tokens[2])\n",
    "            file_info[\"reference_time_watch\"] = int(tokens[3])\n",
    "            file_info[\"service_start_time_watch\"] = int(tokens[4])\n",
    "            file_info[\"file_start_time_watch\"] = int(tokens[5])\n",
    "            file_info[\"file_index\"] = int(tokens[6])\n",
    "            file_info[\"reference_time_diff\"] = file_info[\"reference_time_server\"] - file_info[\"reference_time_watch\"]\n",
    "            file_info[\"file_start_time_watch_adjusted\"] = file_info[\"file_start_time_watch\"] + file_info[\"reference_time_diff\"]\n",
    "            file_info[\"upload_time\"] = int(time.time()*1000)\n",
    "            \n",
    "        \n",
    "            if file_type == \"sensor\":\n",
    "                data = np.genfromtxt(source_folder+f, delimiter=\",\")\n",
    "                process_sensor_data(data, file_info)\n",
    "            elif file_type == \"ble\":\n",
    "                with open(source_folder+f, \"r\") as file:\n",
    "                    data = file.readlines()\n",
    "                process_beacon_data(data, file_info)\n",
    "            else:\n",
    "                raise Exception(\"File starts with unknown word!\")\n",
    "        \n",
    "            create_directory(dest_folders[\"rawdata\"] + to_date_str + \"/\")\n",
    "            os.rename(source_folder+f, dest_folders[\"rawdata\"] + to_date_str + \"/\" + f)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"***** Error in file: \"+f)            \n",
    "            print(str(e))\n",
    "            print(traceback.format_exc())\n",
    "            os.rename(source_folder+f, dest_folders[\"rawdata_error\"]+f)\n",
    "            \n",
    "    for key, _ in meal_buffer.items():\n",
    "            process_meals_ema(key)\n",
    "            \n",
    "    print(\"\\nWaiting for data. Last data process time: \", str(last_process_time))\n",
    "    sleep_count = 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
