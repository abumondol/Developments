{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\asm\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import bite_detection_utils as bdu\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path ='C:/ASM/DevData/eating/eating_detection/'\n",
    "x_th = -0.3\n",
    "var_th = 0.25\n",
    "min_bite_interval = 2*16\n",
    "window_size = 6*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        print('Creating directory: ', path)\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/ASM/DevData/eating/data/steven_uva_lab_data_combined.pkl', 'rb') as file:\n",
    "    lab_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating windows and labels ...\n",
      "x_th, var_th:  -0.3 0.25\n",
      "min_bite_interval, window_size:  32 96\n"
     ]
    }
   ],
   "source": [
    "windows, windows_left, windows_right, ssml = bdu.get_windows_labels_for_dataset(\n",
    "    lab_data, \n",
    "    x_th = x_th, \n",
    "    var_th=var_th,\n",
    "    min_bite_interval = min_bite_interval,\n",
    "    window_size = window_size)\n",
    "\n",
    "print(windows.shape, windows_left.shape, windows_right.shape, ssml.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, X_val, Y_val, batch_size, epochs, tensorboard_logdir):\n",
    "    print(\"Starting training... Sizes: \", X_train.shape, Y_train.shape, X_val.shape, Y_val.shape)    \n",
    "    create_directory(tensorboard_logdir)        \n",
    "    \n",
    "    input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(4, 1), padding ='same', strides=(1, 1), activation='relu', input_shape=input_shape ))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 1), strides=(2, 1)))    \n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), padding ='same', strides=(1, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 1), strides=(2, 1)))    \n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(2, 2), padding ='same', strides=(1, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 1), strides=(2, 1)))    \n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss = categorical_crossentropy, optimizer= Adam())\n",
    "    \n",
    "    if len(X_val)==0:\n",
    "        model.fit(X_train, Y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  shuffle=True,\n",
    "                  validation_data=(X_val, Y_val),\n",
    "                  callbacks=[TensorBoard(log_dir=tensorboard_logdir)])\n",
    "    else:\n",
    "        model.fit(X_train, Y_train,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  shuffle=True,                  \n",
    "                  callbacks=[TensorBoard(log_dir=tensorboard_logdir)])             \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "subject_list = list(range(-1, len(lab_data)))\n",
    "w = windows\n",
    "w = w.resahpe((w.shape[0], w.shape[1], w.shape[2], 1))\n",
    "\n",
    "\n",
    "for exclude_subject in subject_list:\n",
    "    print('\\n\\n**************************************')\n",
    "    print('Excluding subject:', exclude_subject)\n",
    "    print('**************************************\\n')\n",
    "        \n",
    "    cond = ssml[:,0]!=exclude_subject\n",
    "    w = windows[cond, :, :, :]\n",
    "    l = labels[cond, :]\n",
    "    X = np.concatenate((X, w)) \n",
    "    Y = np.concatenate((Y, l))\n",
    "    \n",
    "    \n",
    "    path = root_path+'results/window_'+str(window_size)+'_free_'+str(int(include_free_data))+'_weighted_'+str(int(weighted))+'/'\n",
    "    tensorboard_logdir = path +'tensorboard/subject_'+str(exclude_subject)+'/'\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, stratify=Y, test_size=0.1)\n",
    "    model = train_model(X_train, Y_train, \n",
    "                              X_val, Y_val,\n",
    "                              batch_size = 128,\n",
    "                              epochs=epochs,\n",
    "                              tensorboard_logdir=tensorboard_logdir,\n",
    "                              class_weights=class_weights)    \n",
    "    \n",
    "    model_path = path+'models/'\n",
    "    create_directory(model_path)    \n",
    "    \n",
    "    model.save(model_path+'subject_'+str(exclude_subject)+'.h5')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
