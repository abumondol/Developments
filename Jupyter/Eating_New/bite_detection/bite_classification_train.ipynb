{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\asm\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import bite_detection_utils as bdu\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import my_tensorflow_utils as mtu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path ='C:/ASM/DevData/eating/eating_detection/'\n",
    "x_th = -0.3\n",
    "var_th = 0.25\n",
    "min_bite_interval = 2*16\n",
    "window_size = 6*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/ASM/DevData/eating/data/steven_uva_lab_data_combined.pkl', 'rb') as file:\n",
    "    lab_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating windows and labels ...\n",
      "x_th, var_th:  -0.3 0.25\n",
      "min_bite_interval, window_size:  32 96\n",
      "(18297, 96, 9) (18297, 96, 9) (18297, 96, 9) (18297, 4) [13974  3380   943]\n"
     ]
    }
   ],
   "source": [
    "windows, windows_left, windows_right, ssml, labels = bdu.get_windows_labels_for_dataset(\n",
    "    lab_data, \n",
    "    x_th = x_th, \n",
    "    var_th=var_th,\n",
    "    min_bite_interval = min_bite_interval,\n",
    "    window_size = window_size)\n",
    "\n",
    "print(windows.shape, windows_left.shape, windows_right.shape, ssml.shape, np.sum(labels, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "#Network Parameters\n",
    "num_input = 784\n",
    "num_classes = 10\n",
    "keep_prob_val = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_axis_conv_net(x, name):\n",
    "    x_shape =x.get_shape().as_list()\n",
    "    print('Inside one_axis_net: x_shape', x_shape)\n",
    "    x = tf.reshape(x, shape=[-1, x.shape[1], 1, 1])\n",
    "    \n",
    "    with tf.name_scope(name):\n",
    "        conv_1 = conv_layer(x, size_in=1, size_out=16, ksize=[1,5,1,1], strides=[1,1,1,1], padding=\"SAME\", name='conv_1')\n",
    "        maxpool_1 = maxpool_layer(conv_1, ksize=[2,1], strides=[2,1], padding=\"SAME\", name=\"maxpool_1\")\n",
    "\n",
    "        conv_2 = conv_layer(maxpool_1, size_in=16, size_out=32, ksize=[1,5,1,1], strides=[1,1,1,1], padding=\"SAME\", name='conv_2')\n",
    "        maxpool_2 = maxpool_layer(conv_2, ksize=[2,1], strides=[2,1], padding=\"SAME\", name=\"maxpool_2\")\n",
    "\n",
    "        flattened = tf.reshape(maxpool_2, shape=[-1, x.shape[1]//4])\n",
    "        return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_axes_net(x, y, keep_prob):\n",
    "    x_shape = x.get_shape().as_list()\n",
    "    y_shape = y.get_shape().as_list()\n",
    "    print('Inside all_axes_net: x_shape, y_shape :', x_shape, y_shape)\n",
    "    \n",
    "    all_axes = list(range(x_shape[-1]))\n",
    "    for i in range(x_shape[-1]):\n",
    "        all_axis[i] = one_axis_conv_net(x[:, :, i], name=\"axis_\"+str(i))    \n",
    "        \n",
    "    combo_flattened = tf.concat(all_axes, axis=-1, name='combo_flattened')\n",
    "    combo_shape = combo_flattened.get_shape().as_list()    \n",
    "    \n",
    "    fc_1 = fc_layer(flattened, combo_shape[-1], 512, name='FC_1', relu=True)\n",
    "    fcdrop_1 = tf.nn.dropout(fc_1, keep_prob, name='fcdrop_1')    \n",
    "    fc_2 = fc_layer(fcdrop_1, combo_shape[-1], 256, name='FC_2', relu=True)\n",
    "    fcdrop_2 = tf.nn.dropout(fc_2, keep_prob, name='fcdrop_2')    \n",
    "    logits = fc_layer(fcdrop_2, 256, y_shape[-1], name='FC_3')\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subject_list = list(range(-1, len(lab_data)))\n",
    "subject_list = [-1]\n",
    "\n",
    "for exclude_subject in subject_list:\n",
    "    print('\\n\\n**************************************')\n",
    "    print('Excluding subject:', exclude_subject)\n",
    "    print('**************************************\\n')\n",
    "        \n",
    "    cond = ssml[:,0]!=exclude_subject\n",
    "    w = windows[cond, :, :, :]\n",
    "    l = ssml[cond, -1]\n",
    "    l = \n",
    "    \n",
    "    path = root_path+'results/window_'+str(window_size)+'_free_'+str(int(include_free_data))+'_weighted_'+str(int(weighted))+'/'\n",
    "    tensorboard_logdir = path +'tensorboard/subject_'+str(exclude_subject)+'/'\n",
    "    \n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, stratify=Y, test_size=0.1)\n",
    "    model = train_model(X_train, Y_train, \n",
    "                              X_val, Y_val,\n",
    "                              batch_size = 128,\n",
    "                              epochs=epochs,\n",
    "                              tensorboard_logdir=tensorboard_logdir,\n",
    "                              class_weights=class_weights)    \n",
    "    \n",
    "    model_path = path+'models/'\n",
    "    create_directory(model_path)    \n",
    "    \n",
    "    model.save(model_path+'subject_'+str(exclude_subject)+'.h5')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
