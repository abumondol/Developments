{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import os\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib import rnn\n",
    "\n",
    "tf.set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position = 'right'\n",
    "with open(\"C:\\\\ASM\\\\DevData\\\\accel2gyro\\\\data\\\\steven_free\\\\steven_free_\"+position+\".pkl\", \"rb\") as file:\n",
    "    data = pickle.load(file)\n",
    "#print(data[0][0][:10, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject_count = len(data)    \n",
    "for s in range(subject_count):\n",
    "    sess_count = len(data[s])\n",
    "    for sess in range(sess_count):\n",
    "        d = data[s][sess]\n",
    "        accel = d[:, :3]\n",
    "        gyro = d[:, 3:]\n",
    "        accel_diff = accel[1:, :] - accel[:-1, :]        \n",
    "        data[s][sess] = np.concatenate((accel[1:, :], accel_diff, gyro[1:, :]), axis = 1)\n",
    "        #print(\"Subject {}, Sess {} : {}\".format(s, sess, data[s][sess].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(indices):\n",
    "    count = len(indices)\n",
    "    x = np.zeros((count, 32, 6))\n",
    "    y = np.zeros((count, 16, 3))\n",
    "    for i in range(count):\n",
    "        subject = indices[i][0]\n",
    "        sess = indices[i][1]\n",
    "        xa = indices[i][2]\n",
    "        xb = indices[i][3]\n",
    "        ya = indices[i][4]\n",
    "        yb = indices[i][5]\n",
    "        \n",
    "        x[i, :, :] = data[subject][sess][xa:xb, :6]\n",
    "        y[i, :, :] = data[subject][sess][ya:yb, 6:]\n",
    "        \n",
    "    res = {\"x\":x, \"y\":y}\n",
    "    return res\n",
    "\n",
    "def get_train_indices_test_data(test_subject):\n",
    "    subject_count = len(data)\n",
    "    train_ix = []\n",
    "    test_data = []\n",
    "    for s in range(subject_count):        \n",
    "        sess_count = len(data[s])\n",
    "        for sess in range(sess_count):            \n",
    "            count = len(data[s][sess])            \n",
    "            step_size = 8\n",
    "            if s == test_subject:\n",
    "                step_size = 16\n",
    "            \n",
    "            ix_accel_start = np.arange(0, count-32+1, step_size, dtype=np.int32).reshape(-1, 1)            \n",
    "            ix_accel_end = (ix_accel_start + 32).reshape(-1, 1)\n",
    "            ix_gyro_start = (ix_accel_start + 8).reshape(-1, 1)\n",
    "            ix_gyro_end = (ix_accel_start + 24).reshape(-1, 1)\n",
    "            \n",
    "            ix_count = len(ix_accel_start)\n",
    "            ix_s = np.zeros((ix_count, 1), dtype=np.int32) + s\n",
    "            ix_sess = np.zeros((ix_count, 1), dtype=np.int32) + sess\n",
    "            \n",
    "            ix = np.concatenate((ix_s, ix_sess, ix_accel_start, ix_accel_end, ix_gyro_start, ix_gyro_end) , axis = 1)\n",
    "            \n",
    "            if s == test_subject:\n",
    "                d = get_data(ix)\n",
    "                test_data.append(d)\n",
    "            else:\n",
    "                if len(train_ix)==0:\n",
    "                    train_ix = ix\n",
    "                else:\n",
    "                    train_ix = np.concatenate((train_ix, ix))\n",
    "        \n",
    "    np.random.shuffle(train_ix)        \n",
    "    return train_ix, test_data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_subject = 0\n",
    "train_ix, test_data = get_train_indices_test_data(test_subject)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQLEN_IN = 32\n",
    "SEQLEN_OUT = 16\n",
    "BATCH_SIZE = 128\n",
    "INPUT_SIZE = 6\n",
    "OUTPUT_SIZE = 3\n",
    "INTERNAL_SIZE = 256\n",
    "NLAYERS = 3\n",
    "learning_rate = 0.001  # fixed learning rate\n",
    "dropout_pkeep = 0.8    # some dropout\n",
    "display_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch size:  12231\n"
     ]
    }
   ],
   "source": [
    "epoch_size = len(train_ix) // BATCH_SIZE\n",
    "print(\"Epoch size: \", epoch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, SEQLEN_IN, INPUT_SIZE], name='X')    # [ BATCH_SIZE, SEQLEN, INPUT_SIZE ]\n",
    "Y = tf.placeholder(tf.float32, [None, SEQLEN_OUT, OUTPUT_SIZE], name='Y')\n",
    "\n",
    "fw_cells = [rnn.BasicLSTMCell(INTERNALSIZE) for _ in range(NLAYERS)]\n",
    "bw_cells = [rnn.BasicLSTMCell(INTERNALSIZE) for _ in range(NLAYERS)]\n",
    "\n",
    "multi_fw_cells = rnn.MultiRNNCell(fw_cells, state_is_tuple=False)\n",
    "multi_bw_cells = rnn.MultiRNNCell(bw_cells, state_is_tuple=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
