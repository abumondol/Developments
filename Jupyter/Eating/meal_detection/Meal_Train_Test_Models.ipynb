{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\asm\\continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import Meal_Window_Generation_Utils as mwgenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Meal_Window_Generation_Utils' from 'C:\\\\ASM\\\\Dropbox\\\\Developments\\\\Jupyter\\\\Eating\\\\meal_detection\\\\Meal_Window_Generation_Utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util_path = 'C:/ASM/Dropbox/Developments/Jupyter/Eating/myutils' if 'C:' in os.getcwd() else './myutils'\n",
    "sys.path.append(util_path)\n",
    "import my_file_utils as mfileu\n",
    "import my_classification_utils as mclfu\n",
    "import my_tensorflow_cnn_utils as mcnnu\n",
    "import my_tensorflow_lstm_utils as mlstmu\n",
    "import my_tensorflow_dense_utils as mdenseu\n",
    "import my_feature_utils as mfeatu\n",
    "\n",
    "importlib.reload(mwgenu)\n",
    "#importlib.reload(mfeatu)\n",
    "#importlib.reload(mcnnu)\n",
    "#importlib.reload(mlstmu)\n",
    "#importlib.reload(mdenseu)\n",
    "#importlib.reload(mclfu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size, neg_step, pos_step, test_step  = 10*16, 8, 8, 8\n",
    "vth_min, vth_max, xth = 1, 50, 0\n",
    "axis_count = 9\n",
    "label_shape_1 = 1\n",
    "folder_suffix = \"_meal_free_winsize_\"+str(win_size)+\"_vth_\"+str(vth_min)+\"_\"+str(vth_max)+\"_xth_\"+str(xth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hand='left'\n",
    "ds = mfileu.read_file('data', 'free_data_steven_'+hand+'_smoothed.pkl')\n",
    "annots = mfileu.read_file('data', 'free_data_steven_annots.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj, num_epochs = 1, 1\n",
    "train = 0\n",
    "if 'C:' not in mfileu.get_path():    \n",
    "    subj, num_epochs = int(sys.argv[1]), int(sys.argv[2])\n",
    "\n",
    "params={}\n",
    "params['learning_rate'] = 0.001\n",
    "params['num_epochs'] = num_epochs\n",
    "params['batch_size'] = 128\n",
    "params['keep_prob_val'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(train_indices, test_indices, params, model_path=None):\n",
    "    learning_rate = params['learning_rate']\n",
    "    num_epochs = params['num_epochs']\n",
    "    batch_size = params['batch_size']\n",
    "    keep_prob_val = params['keep_prob_val']\n",
    "    \n",
    "    train_result, test_result = [], []\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, win_size, axis_count], name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, [None, label_shape_1], name=\"y\")\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")    \n",
    "    \n",
    "    \n",
    "    cnn_out = mcnnu.all_sensor_net(x, name=\"all_sensor_net\")\n",
    "    lstm_out_fw, lstm_out_bw = mlstmu.multi_layer_biLSTM(cnn_out, batch_size=batch_size, n_hidden=100, n_layer=2)\n",
    "    print(\"Lstm out shapes(fw, bw): \", lstm_out_fw.get_shape().as_list(), lstm_out_bw.get_shape().as_list())\n",
    "    print(\"FW LSTM out shape:\", lstm_out_fw[:, -1, :].get_shape().as_list())\n",
    "    lstm_out = tf.concat([lstm_out_fw[:, -1, :], lstm_out_bw[:, 0, :]], axis =1)\n",
    "    print(\"Lstm out shape final: \", lstm_out.get_shape().as_list())\n",
    "    \n",
    "    drop_layer = tf.nn.dropout(lstm_out, keep_prob=keep_prob, name=\"dropout\")\n",
    "    print(\"Drop layer shape: \",drop_layer.get_shape().as_list())\n",
    "    logits = mdenseu.fc_layer(drop_layer, 1, name=\"Logits\")    \n",
    "    \n",
    "    print(\"Logit shape: \",logits.get_shape().as_list())\n",
    "    prediction = tf.nn.sigmoid(logits, name=\"prediction\")\n",
    "    correct_prediction = tf.equal(tf.greater(prediction, 0.5), tf.equal(y,1), name=\"correct_prediction\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "    loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y), name=\"loss_op\")    \n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss_op, name=\"train_step\")\n",
    "\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    ########## Train and then save the model ########################\n",
    "    if len(train_indices)>0:    \n",
    "        sess.run(tf.global_variables_initializer())    \n",
    "        train_indices, _ = mclfu.adjust_for_batch_size(train_indices, train_indices, batch_size)\n",
    "\n",
    "        train_count = len(train_indices)\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"Epoch:\", epoch)\n",
    "            total_loss, total_acc = 0, 0\n",
    "            for ix in range(0, train_count, batch_size):                                            \n",
    "                batch_x = mwgenu.get_window_data(ds, train_indices[ix:ix+batch_size], win_size)\n",
    "                batch_y = train_indices[ix:ix+batch_size, -1].reshape((-1,1))                 \n",
    "                sess.run(train_step, feed_dict={x:batch_x, y:batch_y, keep_prob:keep_prob_val})            \n",
    "\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={x:batch_x, y:batch_y, keep_prob:keep_prob_val})        \n",
    "                total_loss+= loss\n",
    "                total_acc += acc\n",
    "                #if ix%(batch_size*1000)==0:\n",
    "                #    print(\"{}/{} :: loss: {:.4f}, acc:{:.4f}\".format(ix, train_count, loss, acc ), end=\"; \")\n",
    "            print('  Train loss: {:.4f}, acc: {:.4f}'.format(batch_size*total_loss/train_count, batch_size*total_acc/train_count))\n",
    "\n",
    "            test_count = len(test_indices)\n",
    "            if test_count>0:            \n",
    "                test_indices, _ = mclfu.adjust_for_batch_size(test_indices, test_indices, batch_size)\n",
    "                total_loss, total_acc = 0, 0\n",
    "                for ix in range(0, test_count, batch_size):                \n",
    "                    batch_x = mwgenu.get_window_data(ds, test_indices[ix:ix+batch_size], win_size)\n",
    "                    batch_y = test_indices[ix:ix+batch_size, -1].reshape((-1,1))  \n",
    "                    \n",
    "                    loss, acc = sess.run([loss_op, accuracy], feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})                \n",
    "                    total_loss+= loss\n",
    "                    total_acc += acc                \n",
    "                print('  Test loss: {:.4f}, acc: {:.4f}'.format(batch_size*total_loss/test_count, batch_size*total_acc/test_count))\n",
    "\n",
    "        print('!!!!!!!!!!!!!!! Optimization Finished !!!!!!!!!!!!!!!!!')\n",
    "\n",
    "        if model_path:\n",
    "            saver = tf.train.Saver()            \n",
    "            mfileu.create_directory(model_path)\n",
    "            saver.save(sess, model_path+'/model')    \n",
    "            print(\"Model Saved!\")\n",
    "        sess.close()\n",
    "        \n",
    "    ########## Restore the model and then Test  ########################\n",
    "    else:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path+'/model')\n",
    "        print(\"Model Loaded!\")\n",
    "        \n",
    "        test_count_original = len(test_indices)        \n",
    "        test_indices, _ = mclfu.adjust_for_batch_size(test_indices, test_indices, batch_size)\n",
    "        test_count = len(test_indices)\n",
    "        res = np.zeros((test_count, 1))\n",
    "        \n",
    "        for ix in range(0, test_count, batch_size):                \n",
    "            batch_x = mwgenu.get_window_data(ds, test_indices[ix:ix+batch_size], win_size)\n",
    "            batch_y = test_indices[ix:ix+batch_size, -1].reshape((-1,1))  \n",
    "            pred = sess.run([prediction], feed_dict={x: batch_x, y: batch_y, keep_prob:1.0})            \n",
    "            res[ix:ix+batch_size, 0] = np.array(pred).reshape((-1, ))\n",
    "        \n",
    "        res = res[:test_count_original, :]        \n",
    "        sess.close()\n",
    "        return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============ Subject: 1 =============\n",
      "\n",
      "============ Epochs: 1  =============\n",
      "Testing.....\n",
      "---------------------------------------------\n",
      "Subj, sess, indices shape:  1 0 (73320, 5)\n",
      "Inside all_sensor_net: x_shape: [None, 80, 9]\n",
      "Inside one_3dsensor_conv_net:  one_3dsensor_conv_net_0 , x_shape [None, 80, 3]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 76, 1, 64] [None, 37, 1, 64]\n",
      "  Conv_4, maxpool_4 shape:  [None, 33, 1, 64] [None, 17, 1, 64]\n",
      "One 3d Sensor flattened shape:  0 [None, 17, 1, 64]\n",
      "Inside one_3dsensor_conv_net:  one_3dsensor_conv_net_1 , x_shape [None, 80, 3]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 76, 1, 64] [None, 37, 1, 64]\n",
      "  Conv_4, maxpool_4 shape:  [None, 33, 1, 64] [None, 17, 1, 64]\n",
      "One 3d Sensor flattened shape:  3 [None, 17, 1, 64]\n",
      "Inside one_3dsensor_conv_net:  one_3dsensor_conv_net_2 , x_shape [None, 80, 3]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 76, 1, 64] [None, 37, 1, 64]\n",
      "  Conv_4, maxpool_4 shape:  [None, 33, 1, 64] [None, 17, 1, 64]\n",
      "One 3d Sensor flattened shape:  6 [None, 17, 1, 64]\n",
      "All sensor list size: 3\n",
      "Combo shape all sensor net:  [None, 17, 3, 64]\n",
      "Inside combine_sensor_conv_net:  combined_sensors_conv_net , x_shape [None, 17, 3, 64]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 13, 1, 64] [None, 6, 1, 64]\n",
      "Final Conv net output shape:  [None, 6, 64]\n",
      "Lstm out shapes(fw, bw):  [128, 6, 100] [128, 6, 100]\n",
      "FW LSTM out shape: [128, 100]\n",
      "Lstm out shape final:  [128, 200]\n",
      "Drop layer shape:  [128, 200]\n",
      "Logit shape:  [128, 1]\n",
      "INFO:tensorflow:Restoring parameters from C:/ASM/DevData/eating/models_free_filtered_windows/subj_1_left/model\n",
      "Model Loaded!\n",
      "Prediction shape:  (73320, 1)\n",
      "Test done for subject, session : 1 0\n",
      "(63378, 78, 9755, 109, 0.8654664484451718, 0.41711229946524064, 0.007932472287196176, 0.015568862275449102)\n",
      "\n",
      "----------------------------------\n",
      "\n",
      "Subj, sess, indices shape:  1 1 (74144, 5)\n",
      "Inside all_sensor_net: x_shape: [None, 80, 9]\n",
      "Inside one_3dsensor_conv_net:  one_3dsensor_conv_net_0 , x_shape [None, 80, 3]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 76, 1, 64] [None, 37, 1, 64]\n",
      "  Conv_4, maxpool_4 shape:  [None, 33, 1, 64] [None, 17, 1, 64]\n",
      "One 3d Sensor flattened shape:  0 [None, 17, 1, 64]\n",
      "Inside one_3dsensor_conv_net:  one_3dsensor_conv_net_1 , x_shape [None, 80, 3]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 76, 1, 64] [None, 37, 1, 64]\n",
      "  Conv_4, maxpool_4 shape:  [None, 33, 1, 64] [None, 17, 1, 64]\n",
      "One 3d Sensor flattened shape:  3 [None, 17, 1, 64]\n",
      "Inside one_3dsensor_conv_net:  one_3dsensor_conv_net_2 , x_shape [None, 80, 3]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 76, 1, 64] [None, 37, 1, 64]\n",
      "  Conv_4, maxpool_4 shape:  [None, 33, 1, 64] [None, 17, 1, 64]\n",
      "One 3d Sensor flattened shape:  6 [None, 17, 1, 64]\n",
      "All sensor list size: 3\n",
      "Combo shape all sensor net:  [None, 17, 3, 64]\n",
      "Inside combine_sensor_conv_net:  combined_sensors_conv_net , x_shape [None, 17, 3, 64]\n",
      "  Axis count:  3\n",
      "  Conv_2, maxpool_2 shape:  [None, 13, 1, 64] [None, 6, 1, 64]\n",
      "Final Conv net output shape:  [None, 6, 64]\n",
      "Lstm out shapes(fw, bw):  [128, 6, 100] [128, 6, 100]\n",
      "FW LSTM out shape: [128, 100]\n",
      "Lstm out shape final:  [128, 200]\n",
      "Drop layer shape:  [128, 200]\n",
      "Logit shape:  [128, 1]\n",
      "INFO:tensorflow:Restoring parameters from C:/ASM/DevData/eating/models_free_filtered_windows/subj_1_left/model\n",
      "Model Loaded!\n",
      "Prediction shape:  (74144, 1)\n",
      "Test done for subject, session : 1 1\n",
      "(59350, 78, 14590, 126, 0.8015213638325421, 0.38235294117647056, 0.005317698391055358, 0.01048951048951049)\n",
      "\n",
      "----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n============ Subject, Epochs, Hand, Win Size: {}, {}, {}, {} =============\".format(subj, num_epochs, hand, win_size))\n",
    "\n",
    "if train:\n",
    "    print(\"Training.....\")\n",
    "    indices = mwgenu.get_train_window_indices_all(ds, annots, win_size=win_size, neg_step=neg_step, pos_step=pos_step, exclude_subject=subj)    \n",
    "    indices = indices[(indices[:, -1]<=1), :]\n",
    "    assert np.sum(indices[:, -1]>1) == 0\n",
    "    print(\"Indices shape before filter, pos_count: \", indices.shape, np.sum(indices[:, -1]))\n",
    "    \n",
    "    v = mfeatu.get_variance_accel(ds, indices, win_size=win_size)\n",
    "    gx = mfeatu.get_grav_x(ds, indices, index_offset=win_size//2)\n",
    "    if hand=='right':\n",
    "        indices = indices[(v>=vth_min)&(v<=vth_max)&(gx<=xth), :]\n",
    "    else:\n",
    "        indices = indices[(v>=vth_min)&(v<=vth_max)&(gx>=xth), :]\n",
    "    print(\"Indices shape after filter, pos_count \", indices.shape, np.sum(indices[:, -1]))\n",
    "    \n",
    "    indices = shuffle(indices)\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.1, stratify=indices[:, -1])\n",
    "    print(\"train, val shapes: \", train_indices.shape, val_indices.shape, np.sum(train_indices[:, -1]), np.sum(val_indices[:, -1]))\n",
    "    \n",
    "    path = mfileu.get_path()\n",
    "    train_test_model(train_indices, val_indices, params, path+\"/models\"+ folder_suffix+\"/subj_\"+str(subj)+\"_\"+hand)\n",
    "    \n",
    "else:\n",
    "    print(\"Testing.....\")\n",
    "    path = mfileu.get_path()\n",
    "    \n",
    "    #Test on Free Data\n",
    "    for subj in range(11):\n",
    "        res=[]\n",
    "        print(\"---------------- Testing Free -----------------------------\")\n",
    "        for sess in range(len(ds[subj])):\n",
    "            indices = mwgenu.get_test_window_indices(ds, annots, win_size, step_size=test_step, subj=subj, sess=sess)        \n",
    "            print(\"Free Subj, sess, indices shape: \", subj, sess, indices.shape)\n",
    "            \n",
    "            v = mfeatu.get_variance_accel(ds, indices, win_size=win_size)\n",
    "            gx = mfeatu.get_grav_x(ds, indices, index_offset=win_size//2)\n",
    "            \n",
    "            pred = train_test_model([], indices, params, path+\"/models\"+ folder_suffix+\"/subj_\"+str(subj)+\"_\"+hand)\n",
    "            print(\"Prediction shape: \", pred.shape)        \n",
    "\n",
    "            res.append({\"pred\":pred, 'indices':indices, \"var\":v, \"gx\":gx})\n",
    "            print (\"Test done for subject, session :\", subj, sess)\n",
    "            #gt = indices[:, -1].reshape((-1, 1))\n",
    "            #print(mclfu.get_scores_1d(pred, gt))\n",
    "            print(\"\\n----------------------------------\\n\")\n",
    "\n",
    "        mfileu.write_file('results'+ folder_suffix+\"_free\", 'subj_'+str(subj)+\"_\"+hand+\".pkl\", res)\n",
    "        \n",
    "        \n",
    "    #Test on Lab Data\n",
    "    ds = mfileu.read_file('data', 'lab_data_steven_smoothed.pkl')\n",
    "    ds_right, ds_left, annots = mslabu.separate_right_left_annots(dsa)    \n",
    "    ds = ds_right if hand=='right' else ds_left\n",
    "    for subj in range(7):\n",
    "        res=[]\n",
    "        print(\"----------------- Testing Lab ----------------------------\")\n",
    "        for sess in range(len(ds[subj])):\n",
    "            indices = mwgenu.get_test_window_indices(ds, [], win_size, step_size=test_step, subj=subj, sess=sess)        \n",
    "            print(\"Lab subj, sess, indices shape: \", subj, sess, indices.shape)\n",
    "            \n",
    "            v = mfeatu.get_variance_accel(ds, indices, win_size=win_size)\n",
    "            gx = mfeatu.get_grav_x(ds, indices, index_offset=win_size//2)\n",
    "            \n",
    "            model_subject = subj-2 if subj>=2 else 10 \n",
    "            pred = train_test_model([], indices, params, path+\"/models\"+ folder_suffix+\"/subj_\"+str(model_subject)+\"_\"+hand)\n",
    "            print(\"Prediction shape: \", pred.shape)        \n",
    "\n",
    "            res.append({\"pred\":pred, 'indices':indices, \"var\":v, \"gx\":gx})\n",
    "            print (\"Test done for subject, session :\", subj, sess)            \n",
    "            print(\"\\n----------------------------------\\n\")\n",
    "\n",
    "        mfileu.write_file('results'+ folder_suffix+\"_lab\", 'subj_'+str(subj)+\"_\"+hand+\".pkl\", res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
