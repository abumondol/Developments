{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import my_bite_detection_utils as bdu\n",
    "import my_classification_utils as mcu\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "import my_tensorflow_utils as mtu\n",
    "import importlib\n",
    "from sklearn import metrics\n",
    "import my_keras_utils as mku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'my_keras_utils' from 'C:\\\\ASM\\\\Dropbox\\\\Developments\\\\Jupyter\\\\Eating\\\\bite_detection\\\\my_keras_utils.py'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mtu)\n",
    "importlib.reload(bdu)\n",
    "importlib.reload(mcu)\n",
    "importlib.reload(mku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root path:  C:/ASM/DevData/eating\n",
      "Creating windows and labels ... x_th: 0, min_bite_interval: 48, window_size: 96\n",
      "Sindow, ssml, label shape:  (36679, 96, 6) (36679, 4) (36679,)\n",
      "Neg, Pos, Bite, Sip, X count:  32864 3648 2819 829 167\n",
      "Neg, Pos, Bite, Sip, X count:  32864 3648 3648 0 0\n"
     ]
    }
   ],
   "source": [
    "root_path ='C:/ASM/DevData/eating' if \"C:\" in os.getcwd() else \".\"\n",
    "print(\"Root path: \", root_path)\n",
    "\n",
    "params = {\"x_th\": -0, \"min_bite_interval\": 3*16, \"window_size\": 6*16}\n",
    "windows, ssml, features = bdu.get_windows_lab(params)\n",
    "labels = ssml[:,-1]\n",
    "print(\"Sindow, ssml, label shape: \", windows.shape, ssml.shape, labels.shape)\n",
    "print(\"Neg, Pos, Bite, Sip, X count: \", np.sum(labels==0), np.sum(labels>0), np.sum(labels==1), np.sum(labels==2), np.sum(labels==-1))\n",
    "\n",
    "labels[labels==2] = 1\n",
    "cond = labels>=0\n",
    "windows = windows[cond]\n",
    "ssml = ssml[cond]\n",
    "labels = labels[cond].reshape((-1,1))\n",
    "features = features[cond]\n",
    "print(\"Neg, Pos, Bite, Sip, X count: \", np.sum(labels==0), np.sum(labels>0), np.sum(labels==1), np.sum(labels==2), np.sum(labels==-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Parameters\n",
    "net_params={}\n",
    "net_params['learning_rate'] = 0.001\n",
    "net_params['num_epochs'] = 50\n",
    "net_params['batch_size'] = 128\n",
    "net_params['keep_prob_val'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4097, 96, 6) (4097, 4) [2212]\n",
      "******** Exclude Subject 7 *********\n",
      "{'x_th': -0.3, 'min_bite_interval': 48, 'window_size': 96, 'var_th': 0.5}\n",
      "Train Test shapes:  (3892, 96, 6) (205, 96, 6)\n",
      "Train Test labels: [2127] [85]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_3_input to have 4 dimensions, but got array with shape (3892, 96, 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-9c721728871f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroot_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/outputs/bite_detection_lopo/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mbdu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/subject_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude_subject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m#test_pred, train_result, test_result = mtu.train_test_model(train_x, train_y, test_x, test_y, folder_path=path, params=net_params)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mypr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmku\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmcu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mypr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ASM\\Dropbox\\Developments\\Jupyter\\Eating\\bite_detection\\my_keras_utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(X_train, Y_train, X_test, Y_test, batch_size, epochs)\u001b[0m\n\u001b[0;32m     41\u001b[0m     model.compile(loss=binary_crossentropy,\n\u001b[0;32m     42\u001b[0m                   \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                   metrics=['accuracy'])\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     model.fit(X_train, Y_train,\n",
      "\u001b[1;32mc:\\asm\\continuum\\anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\asm\\continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\asm\\continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1474\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1475\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1476\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1477\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\asm\\continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    111\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    114\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_3_input to have 4 dimensions, but got array with shape (3892, 96, 6)"
     ]
    }
   ],
   "source": [
    "params[\"x_th\"] = -.3\n",
    "for var_th in np.arange(0, 2.1, .25):    \n",
    "    var_th = int(var_th*100)/100    \n",
    "    if var_th !=0.5: \n",
    "        continue\n",
    "    \n",
    "    params[\"var_th\"] = var_th \n",
    "    cond = (features[:, 0] <=params[\"x_th\"]) & (features[:, -1] >=params[\"var_th\"]) & (ssml[:, 0]>=7)\n",
    "    w = windows[cond]\n",
    "    s = ssml[cond]\n",
    "    l = labels[cond]\n",
    "    f = features[cond]\n",
    "    print(w.shape, s.shape, np.sum(l, axis=0))\n",
    "    \n",
    "    for exclude_subject in range(7, 28):\n",
    "        print(\"******** Exclude Subject {} *********\".format(exclude_subject))\n",
    "        print(params)\n",
    "        cond = s[:,0]!=exclude_subject\n",
    "        train_x = w[cond]\n",
    "        train_y = l[cond]\n",
    "        \n",
    "        cond = s[:,0]==exclude_subject\n",
    "        test_x = w[cond]        \n",
    "        test_y = l[cond]\n",
    "\n",
    "        print(\"Train Test shapes: \", train_x.shape, test_x.shape)\n",
    "        print(\"Train Test labels:\", np.sum(train_y, axis=0), np.sum(test_y, axis=0))\n",
    "        \n",
    "        path = root_path+'/outputs/bite_detection_lopo/'+bdu.param_string(params)+\"/subject_\"+str(exclude_subject)     \n",
    "        #test_pred, train_result, test_result = mtu.train_test_model(train_x, train_y, test_x, test_y, folder_path=path, params=net_params)\n",
    "        ypr = mku.train_model(train_x, train_y, test_x, test_y, batch_size=128, epochs = 100)\n",
    "        res = mcu.get_metrics(ypr, test_y)\n",
    "        \n",
    "        #path = path+'/results'\n",
    "        #bdu.create_directory(path)\n",
    "        #np.savetxt(path+'/test_y.csv', test_y, fmt='%.4f', delimiter=',')    \n",
    "        #np.savetxt(path+'/test_prediction.csv', test_pred, fmt='%.4f', delimiter=',')\n",
    "        #np.savetxt(path+'/train_result.csv', train_result, fmt='%.4f', delimiter=',')\n",
    "        #np.savetxt(path+'/test_result.csv', test_result, fmt='%.4f', delimiter=',') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_result = np.array(test_result)\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
